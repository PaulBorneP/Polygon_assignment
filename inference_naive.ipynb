{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulbp_dty/Desktop/src/ml_assign/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from tqdm import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granny Smith                                                                (96.73%)\n",
      "lemon                                                                       (0.10%)\n",
      "pomegranate                                                                 (0.08%)\n",
      "fig                                                                         (0.06%)\n",
      "piggy bank, penny bank                                                      (0.05%)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess image\n",
    "tfms = transforms.Compose([transforms.Resize(224), transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
    "test_image = tfms(Image.open('./dataset/ILSVRC2012_val_00000023.JPEG')).unsqueeze(0)\n",
    "\n",
    "# Load ImageNet class names\n",
    "labels_map = json.load(open('categories.json'))\n",
    "labels_map = [labels_map[str(i)] for i in range(1000)]\n",
    "\n",
    "# Classify\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(test_image)\n",
    "\n",
    "# Print predictions\n",
    "for idx in torch.topk(outputs, k=5).indices.squeeze(0).tolist():\n",
    "    prob = torch.softmax(outputs, dim=1)[0, idx].item()\n",
    "    print('{label:<75} ({p:.2f}%)'.format(label=labels_map[idx], p=prob*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive implementation on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [09:30<00:00,  8.76it/s]\n"
     ]
    }
   ],
   "source": [
    "directory= './dataset/'\n",
    "nb_samples=5000 # test on a smaller part of the dataset\n",
    "labels=json.load(open('labels.json'))\n",
    "\n",
    "grayscale= []\n",
    "actual=[]\n",
    "predicted=[]\n",
    "\n",
    "tfms = transforms.Compose([transforms.Resize(224), transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
    "\n",
    "for filename in tqdm(os.listdir(directory)[:nb_samples]):\n",
    "    f = os.path.join(directory, filename)\n",
    "    y_true= labels[filename]    \n",
    "    img=Image.open(f)    \n",
    "    if img.mode !='RGB':\n",
    "        grayscale.append(filename)\n",
    "        img = tfms(img.convert('RGB')).unsqueeze(0)\n",
    "    else:\n",
    "        img = tfms(img).unsqueeze(0)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img)\n",
    "        y_pred = torch.argmax(outputs).item()\n",
    "        actual.append(y_true)\n",
    "        predicted.append(y_pred)\n",
    "\n",
    "with open('partial_results.json', 'w') as fp:\n",
    "    results = { i : (actual[i], predicted[i]) for i in range(nb_samples)}\n",
    "    json.dump(results, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=list(json.load(open('results.json')).values())\n",
    "actual=[sample[0] for sample in results]\n",
    "predicted=[sample[1] for sample in results]\n",
    "\n",
    "def confusion_values (y_true,y_pred):\n",
    "    confusion = confusion_matrix(y_true,y_pred)\n",
    "    FP = confusion.sum(axis=0) - np.diag(confusion)  \n",
    "    FN = confusion.sum(axis=1) - np.diag(confusion)\n",
    "    TP = np.diag(confusion)\n",
    "    TN = confusion.sum() - (FP + FN + TP)\n",
    "    return FP,FN,TP,TN\n",
    "\n",
    "def get_metrics(FP,FN,TP,TN,nb_smpl):\n",
    "    # Accuracy\n",
    "    ACC=sum(TP)/nb_smpl\n",
    "    # Specificity or True Negative Rate\n",
    "    TNR=TN/(TN+FP)\n",
    "    return {'ACC':ACC,'TNR':TNR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACC': 0.74278, 'TNR': array([0.99995996, 0.99991992, 0.99985986, 0.9996997 , 0.99971972,\n",
      "       0.9995996 , 0.99983984, 0.99993994, 0.99975976, 0.99995996,\n",
      "       0.99977978, 0.99993994, 0.99987988, 0.99987988, 0.9998999 ,\n",
      "       0.99991992, 0.99997998, 0.99993994, 0.99997998, 0.99997998,\n",
      "       0.9998999 , 0.99973974, 0.9998999 , 0.99983984, 1.        ,\n",
      "       0.99997998, 0.9994995 , 0.99987988, 0.99983984, 0.9998999 ,\n",
      "       0.9997998 , 0.99983984, 0.99933934, 0.99963964, 0.99983984,\n",
      "       0.99957958, 0.99965966, 0.99975976, 0.99983984, 0.9997998 ,\n",
      "       0.9994995 , 0.99967968, 0.99971972, 0.99985986, 0.99977978,\n",
      "       0.99995996, 0.99967968, 0.99981982, 0.9998999 , 0.99971972,\n",
      "       0.99995996, 0.99993994, 0.99953954, 0.9996997 , 0.99987988,\n",
      "       0.99987988, 0.99995996, 0.99985986, 0.9995996 , 0.99967968,\n",
      "       0.9994995 , 0.99985986, 0.99975976, 0.99971972, 0.99945946,\n",
      "       0.99983984, 0.99927928, 0.9997998 , 0.99953954, 0.9997998 ,\n",
      "       0.99973974, 0.99971972, 0.99965966, 0.99915916, 0.99981982,\n",
      "       0.99975976, 0.99991992, 0.99967968, 0.99961962, 0.99983984,\n",
      "       0.99987988, 0.99985986, 0.99971972, 0.99985986, 1.        ,\n",
      "       0.99991992, 0.99973974, 1.        , 0.99991992, 0.99991992,\n",
      "       0.99995996, 0.9998999 , 0.99995996, 0.99995996, 0.99991992,\n",
      "       0.99977978, 0.99993994, 0.99995996, 0.99985986, 0.9997998 ,\n",
      "       0.99995996, 0.99935936, 0.99997998, 0.9996997 , 0.99991992,\n",
      "       0.99991992, 0.99985986, 0.99983984, 0.9998999 , 0.99981982,\n",
      "       0.99981982, 0.9998999 , 0.99983984, 0.99981982, 0.9997998 ,\n",
      "       0.99981982, 0.99985986, 0.99997998, 0.99977978, 0.99945946,\n",
      "       0.99977978, 0.99981982, 0.99981982, 0.99991992, 0.99985986,\n",
      "       0.99973974, 0.99977978, 0.99995996, 0.99967968, 0.99993994,\n",
      "       0.99997998, 0.99991992, 0.9996997 , 0.99995996, 0.99997998,\n",
      "       0.99995996, 0.99991992, 0.99993994, 0.99993994, 0.9998999 ,\n",
      "       0.99983984, 0.99995996, 0.9998999 , 0.9998999 , 0.99985986,\n",
      "       1.        , 0.99987988, 0.99987988, 0.99985986, 0.99977978,\n",
      "       0.99971972, 0.99967968, 0.99993994, 0.99961962, 0.99981982,\n",
      "       0.99971972, 0.9998999 , 0.9997998 , 0.99983984, 0.99945946,\n",
      "       0.99987988, 0.99975976, 0.99945946, 0.9998999 , 0.99991992,\n",
      "       0.9997998 , 0.9995996 , 0.99991992, 0.99977978, 0.99987988,\n",
      "       0.99973974, 0.99963964, 0.99973974, 0.99963964, 0.99985986,\n",
      "       0.99981982, 0.9997998 , 0.99971972, 0.9998999 , 0.9996997 ,\n",
      "       0.9995996 , 0.99993994, 0.99991992, 0.99991992, 0.99975976,\n",
      "       0.99973974, 0.99965966, 0.9996997 , 0.99995996, 0.9996997 ,\n",
      "       0.99995996, 0.99987988, 0.99971972, 0.99975976, 0.99983984,\n",
      "       0.9997998 , 0.99985986, 0.99965966, 0.9995996 , 0.9996997 ,\n",
      "       0.99975976, 0.99985986, 0.99965966, 0.99971972, 0.99973974,\n",
      "       0.99973974, 0.99983984, 0.9995996 , 0.9996997 , 0.99985986,\n",
      "       0.99975976, 0.99963964, 0.99971972, 0.99981982, 0.99985986,\n",
      "       0.99965966, 0.99983984, 0.9997998 , 0.99977978, 0.99973974,\n",
      "       0.99983984, 0.99987988, 0.99973974, 0.99973974, 0.99981982,\n",
      "       0.99961962, 0.9997998 , 0.99965966, 0.99983984, 0.9997998 ,\n",
      "       0.9997998 , 0.99951952, 0.99957958, 0.99931932, 0.99967968,\n",
      "       0.99971972, 0.99975976, 0.9997998 , 0.9993994 , 0.9997998 ,\n",
      "       0.99965966, 0.99965966, 0.99981982, 0.99973974, 0.99987988,\n",
      "       0.99981982, 0.99967968, 0.9998999 , 0.9996997 , 0.9996997 ,\n",
      "       0.99925926, 0.99991992, 0.99985986, 0.99981982, 0.9998999 ,\n",
      "       0.99993994, 0.99971972, 0.99971972, 0.99993994, 0.99991992,\n",
      "       0.9998999 , 0.99995996, 0.99995996, 0.99963964, 0.99985986,\n",
      "       0.99961962, 0.99961962, 0.9996997 , 0.99991992, 0.9996997 ,\n",
      "       0.9996997 , 0.9997998 , 0.99961962, 0.99963964, 0.9997998 ,\n",
      "       0.99993994, 0.99991992, 0.99953954, 0.99965966, 0.99983984,\n",
      "       0.99961962, 0.99951952, 0.99987988, 0.99983984, 0.9997998 ,\n",
      "       0.99941942, 0.99987988, 0.99975976, 0.99981982, 0.99991992,\n",
      "       0.99981982, 0.99991992, 0.9996997 , 0.99981982, 0.99977978,\n",
      "       0.99965966, 0.99993994, 0.99991992, 0.99977978, 0.99983984,\n",
      "       0.99977978, 0.99975976, 0.99981982, 0.99975976, 0.99981982,\n",
      "       0.99973974, 0.9998999 , 0.9998999 , 0.9998999 , 0.99981982,\n",
      "       0.9996997 , 0.99963964, 0.99955956, 0.9996997 , 0.99975976,\n",
      "       0.99981982, 0.99973974, 0.9998999 , 0.99981982, 0.99983984,\n",
      "       0.9997998 , 0.99997998, 0.99987988, 1.        , 0.99993994,\n",
      "       0.99997998, 0.99997998, 0.99991992, 0.99991992, 0.99981982,\n",
      "       0.99975976, 0.99973974, 0.9998999 , 0.99983984, 0.99991992,\n",
      "       0.99977978, 0.99975976, 0.99987988, 0.99991992, 0.99995996,\n",
      "       0.99997998, 0.99981982, 0.99973974, 0.99983984, 0.99991992,\n",
      "       0.99987988, 0.99977978, 0.9998999 , 0.99997998, 0.9993994 ,\n",
      "       0.9998999 , 0.9998999 , 0.99975976, 0.99985986, 0.9997998 ,\n",
      "       0.99993994, 0.9997998 , 0.99965966, 0.99947948, 0.99967968,\n",
      "       0.99983984, 0.9998999 , 0.99983984, 0.99985986, 0.9998999 ,\n",
      "       0.99993994, 0.99993994, 0.99981982, 0.99977978, 0.99983984,\n",
      "       0.99987988, 0.9996997 , 0.99971972, 0.9996997 , 0.99985986,\n",
      "       0.99997998, 0.99983984, 0.99981982, 0.99967968, 0.99971972,\n",
      "       0.99947948, 0.99981982, 0.99951952, 0.99991992, 0.99963964,\n",
      "       0.99957958, 0.99983984, 0.99993994, 0.99993994, 0.99981982,\n",
      "       0.99991992, 0.9998999 , 0.99993994, 0.99993994, 0.99973974,\n",
      "       0.99965966, 0.99991992, 0.99987988, 0.99987988, 0.99971972,\n",
      "       0.9993994 , 0.99985986, 0.99977978, 0.99981982, 0.99971972,\n",
      "       0.99987988, 0.99951952, 0.9995996 , 0.99977978, 0.99947948,\n",
      "       0.99971972, 0.99985986, 0.99961962, 0.9995996 , 0.99977978,\n",
      "       0.99943944, 0.99955956, 0.99973974, 0.9995996 , 0.99971972,\n",
      "       0.99983984, 0.99943944, 0.99967968, 0.99963964, 0.99967968,\n",
      "       0.99991992, 0.99983984, 0.99977978, 0.99973974, 0.99985986,\n",
      "       1.        , 0.9994995 , 0.99977978, 0.99975976, 0.99987988,\n",
      "       0.99923924, 0.9995996 , 0.9997998 , 0.99977978, 0.99981982,\n",
      "       0.99975976, 0.99961962, 0.99931932, 0.99985986, 0.99965966,\n",
      "       0.99945946, 0.99973974, 0.9996997 , 0.99971972, 0.99955956,\n",
      "       0.99977978, 0.99985986, 0.99961962, 0.99951952, 0.99967968,\n",
      "       0.9997998 , 0.99941942, 0.99985986, 0.99987988, 0.99985986,\n",
      "       0.99985986, 0.9996997 , 0.99981982, 0.99957958, 0.99985986,\n",
      "       0.9996997 , 0.99991992, 0.99975976, 0.99981982, 0.9992993 ,\n",
      "       0.9993994 , 0.9998999 , 0.99963964, 0.9994995 , 0.99967968,\n",
      "       0.99975976, 0.99983984, 0.99917918, 0.99955956, 0.99993994,\n",
      "       0.99957958, 0.99983984, 0.99957958, 0.9996997 , 0.99975976,\n",
      "       0.9996997 , 0.99993994, 0.99957958, 0.99973974, 0.99971972,\n",
      "       0.99993994, 0.99995996, 0.99973974, 0.99981982, 0.9996997 ,\n",
      "       0.99981982, 0.99981982, 0.9996997 , 0.99963964, 0.9996997 ,\n",
      "       0.99987988, 0.99975976, 0.99985986, 0.99977978, 0.99945946,\n",
      "       0.99935936, 0.99975976, 0.99975976, 0.9994995 , 0.99973974,\n",
      "       0.99977978, 0.99965966, 0.99987988, 0.99981982, 0.99993994,\n",
      "       0.9995996 , 0.99955956, 0.9996997 , 0.99965966, 0.99937938,\n",
      "       0.99973974, 0.9998999 , 0.99953954, 0.99927928, 0.99941942,\n",
      "       0.9996997 , 0.9987988 , 0.99897898, 0.99993994, 0.99941942,\n",
      "       0.9997998 , 0.99973974, 0.99941942, 0.99977978, 0.9997998 ,\n",
      "       0.99987988, 0.99983984, 0.99983984, 0.99977978, 0.99977978,\n",
      "       0.99973974, 0.99973974, 0.9996997 , 0.99945946, 0.99971972,\n",
      "       0.9996997 , 0.99973974, 0.99987988, 0.99953954, 0.99975976,\n",
      "       0.99983984, 0.9997998 , 0.99983984, 0.99971972, 0.99987988,\n",
      "       0.99993994, 0.99967968, 0.99975976, 0.9994995 , 0.99977978,\n",
      "       0.99993994, 0.99993994, 0.99977978, 0.99987988, 0.99977978,\n",
      "       0.99995996, 0.99993994, 0.99983984, 0.99975976, 0.99955956,\n",
      "       0.99963964, 0.99981982, 0.99983984, 0.99993994, 0.99987988,\n",
      "       0.99977978, 0.99991992, 0.99965966, 0.99985986, 0.99981982,\n",
      "       0.99981982, 0.99991992, 0.99923924, 0.99977978, 0.99931932,\n",
      "       0.9997998 , 0.99971972, 0.99987988, 0.99961962, 0.9997998 ,\n",
      "       0.9997998 , 0.99975976, 0.99985986, 0.99973974, 0.99981982,\n",
      "       0.9996997 , 0.99973974, 0.99977978, 0.99981982, 0.9996997 ,\n",
      "       0.99947948, 0.99915916, 0.99957958, 0.99981982, 0.99997998,\n",
      "       0.99983984, 0.99981982, 0.9998999 , 0.99975976, 0.99983984,\n",
      "       0.99981982, 0.99985986, 0.99963964, 0.99975976, 0.99971972,\n",
      "       0.99991992, 0.99975976, 0.99925926, 0.99971972, 0.99985986,\n",
      "       0.99937938, 0.99973974, 0.99993994, 0.99991992, 0.99893894,\n",
      "       0.99991992, 0.99947948, 0.99985986, 0.99981982, 0.99983984,\n",
      "       0.99985986, 0.99943944, 0.99977978, 0.99977978, 0.99931932,\n",
      "       0.99971972, 0.99961962, 0.9998999 , 0.99945946, 0.99933934,\n",
      "       0.99997998, 0.9996997 , 0.99977978, 0.99981982, 0.99961962,\n",
      "       0.99975976, 0.99977978, 0.9996997 , 0.99941942, 0.99993994,\n",
      "       0.99973974, 0.99981982, 0.99971972, 0.9996997 , 0.99943944,\n",
      "       0.99951952, 0.99977978, 0.99935936, 0.99965966, 0.9996997 ,\n",
      "       0.99965966, 0.99981982, 0.99965966, 0.99935936, 0.99961962,\n",
      "       0.99985986, 0.99977978, 0.99983984, 0.99977978, 0.99985986,\n",
      "       0.99983984, 0.99941942, 0.99987988, 0.99981982, 0.9993994 ,\n",
      "       0.99983984, 0.99991992, 0.99971972, 0.9995996 , 0.99943944,\n",
      "       0.99955956, 0.9992993 , 0.99977978, 0.99971972, 0.9997998 ,\n",
      "       0.99997998, 0.99967968, 0.99993994, 0.99971972, 0.99941942,\n",
      "       0.99931932, 0.99943944, 0.99891892, 0.99977978, 0.99991992,\n",
      "       0.9997998 , 0.99985986, 0.9993994 , 0.9991992 , 0.99985986,\n",
      "       0.9997998 , 0.99977978, 0.99957958, 0.99961962, 0.99985986,\n",
      "       0.99985986, 0.99977978, 0.99983984, 0.99967968, 0.99973974,\n",
      "       0.9995996 , 0.99967968, 0.99973974, 0.99933934, 0.99983984,\n",
      "       0.9997998 , 0.99981982, 0.99985986, 0.9993994 , 0.99977978,\n",
      "       0.99967968, 0.99991992, 0.9997998 , 0.9997998 , 0.99987988,\n",
      "       0.9996997 , 0.99987988, 0.99983984, 0.99957958, 0.99977978,\n",
      "       0.99977978, 0.99945946, 0.99973974, 0.99945946, 0.99965966,\n",
      "       0.9994995 , 0.99983984, 0.99973974, 0.99933934, 0.99935936,\n",
      "       0.99993994, 0.9998999 , 0.99975976, 0.99943944, 0.99971972,\n",
      "       0.99965966, 0.99981982, 0.99973974, 0.99917918, 0.99973974,\n",
      "       0.99963964, 0.9993994 , 0.99971972, 0.99991992, 0.9997998 ,\n",
      "       0.99985986, 0.9996997 , 0.99985986, 0.99991992, 0.99967968,\n",
      "       0.9997998 , 0.99981982, 0.99915916, 0.99983984, 0.99971972,\n",
      "       0.9996997 , 0.99971972, 0.99923924, 0.99985986, 0.9996997 ,\n",
      "       0.99993994, 0.99985986, 0.9998999 , 0.9997998 , 0.99975976,\n",
      "       0.99965966, 0.9998999 , 0.99971972, 0.99993994, 0.99985986,\n",
      "       0.99973974, 0.99981982, 0.99965966, 0.9997998 , 0.99967968,\n",
      "       0.99975976, 0.9998999 , 0.99963964, 0.99973974, 0.99921922,\n",
      "       0.9996997 , 0.99987988, 0.99971972, 0.99973974, 0.99967968,\n",
      "       0.99975976, 0.99975976, 0.99977978, 0.99995996, 0.99957958,\n",
      "       0.99995996, 0.99981982, 0.99987988, 0.99965966, 0.99965966,\n",
      "       0.99981982, 0.9998999 , 0.99923924, 0.99977978, 0.99987988,\n",
      "       0.99911912, 0.9997998 , 0.9998999 , 0.99973974, 0.99987988,\n",
      "       0.99991992, 0.9998999 , 0.99957958, 0.99961962, 0.99911912,\n",
      "       0.99993994, 0.9997998 , 0.99993994, 0.99985986, 0.99963964,\n",
      "       0.99991992, 0.99977978, 0.99963964, 0.99973974, 0.99985986,\n",
      "       0.99957958, 0.99935936, 0.99995996, 0.99991992, 0.99933934,\n",
      "       0.99977978, 0.99981982, 0.99975976, 0.99975976, 0.99981982,\n",
      "       0.99957958, 0.99987988, 0.9994995 , 0.99905906, 0.99975976,\n",
      "       0.99977978, 0.99943944, 0.99963964, 0.99851852, 0.99981982,\n",
      "       0.9997998 , 0.99923924, 0.99981982, 0.99991992, 0.99975976,\n",
      "       0.99977978, 0.9993994 , 0.99987988, 0.99981982, 0.99987988,\n",
      "       0.99905906, 0.99975976, 0.99953954, 0.99993994, 0.99967968,\n",
      "       0.9993994 , 0.99965966, 0.99977978, 0.99965966, 0.9998999 ,\n",
      "       0.99953954, 0.99967968, 0.99977978, 0.9998999 , 0.9996997 ,\n",
      "       0.9996997 , 0.9994995 , 0.9997998 , 0.99985986, 0.99983984,\n",
      "       0.99965966, 0.99961962, 0.99963964, 0.99953954, 0.99925926,\n",
      "       0.99981982, 0.99977978, 0.99971972, 0.99991992, 0.99985986,\n",
      "       0.99985986, 0.99987988, 0.99957958, 0.99947948, 0.99931932,\n",
      "       0.99953954, 0.99963964, 0.99995996, 0.99963964, 0.99967968,\n",
      "       0.99997998, 0.9998999 , 0.99965966, 0.9997998 , 0.99963964,\n",
      "       0.99961962, 0.99991992, 0.99981982, 0.99991992, 0.99983984,\n",
      "       0.99975976, 0.99951952, 0.9995996 , 0.9997998 , 0.9998999 ,\n",
      "       0.99987988, 0.9995996 , 0.99973974, 0.9998999 , 0.99947948,\n",
      "       0.99977978, 0.99941942, 0.99991992, 0.99885886, 0.99975976,\n",
      "       0.99937938, 0.99907908, 0.99953954, 0.99961962, 0.99957958,\n",
      "       0.99961962, 0.99975976, 0.99981982, 0.99985986, 0.99973974,\n",
      "       0.99973974, 0.99987988, 0.99987988, 0.9997998 , 0.99983984,\n",
      "       0.99975976, 0.99983984, 0.99993994, 0.99965966, 0.9998999 ,\n",
      "       0.9998999 , 0.9997998 , 0.9997998 , 0.99991992, 0.99991992,\n",
      "       0.99985986, 0.99985986, 0.99981982, 0.99995996, 0.99993994,\n",
      "       0.99991992, 0.9997998 , 0.99987988, 0.99993994, 0.99991992,\n",
      "       0.99961962, 0.99971972, 0.99955956, 0.99991992, 0.9995996 ,\n",
      "       0.99971972, 0.99951952, 0.99963964, 0.99963964, 0.99937938,\n",
      "       0.99923924, 0.9998999 , 0.9993994 , 0.9995996 , 0.99981982,\n",
      "       0.99885886, 0.99965966, 0.99967968, 0.99905906, 0.9994995 ,\n",
      "       0.99983984, 0.99975976, 0.9998999 , 0.9997998 , 0.99997998,\n",
      "       0.99993994, 1.        , 0.99965966, 0.99987988, 0.99985986,\n",
      "       0.99985986, 0.99985986, 0.99961962, 0.9998999 , 0.99971972,\n",
      "       0.9997998 , 0.99961962, 0.9996997 , 0.99947948, 0.99975976])}\n"
     ]
    }
   ],
   "source": [
    "FP,FN,TP,TN = confusion_values(actual,predicted)\n",
    "metrics = get_metrics(FP,FN,TP,TN,len(actual))\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class imbalance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequence\n",
    "The idea was to compute the metrics on the most and least present part of the dataset but they are all present in equal amount in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_dict = {x:actual.count(x) for x in actual}\n",
    "predicted_dict = {x:predicted.count(x) for x in predicted}\n",
    "results_dict = {actual[i]: predicted[i] for i in range(len(actual))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754\n"
     ]
    }
   ],
   "source": [
    "actual_filtered = [ key for (key,value) in actual_dict.items() if value ==50  ]\n",
    "results_filtered = {key:value for (key,value) in results_dict.items() if key in actual_filtered }\n",
    "fFP,fFN,fTP,fTN = confusion_values(list(results_filtered.keys()),list(results_filtered.values()))\n",
    "fmetrics = get_metrics(fFP,fFN,fTP,fTN,len(actual_filtered))\n",
    "print(fmetrics['ACC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most predicted classes:\n",
      "hot pot, hotpot : 92\n",
      "tape player : 101\n",
      "lakeside, lakeshore : 91\n",
      "shoji : 86\n",
      "desk : 93\n",
      "library : 92\n",
      "packet : 86\n",
      "swing : 91\n",
      "plate : 88\n",
      "------------------\n",
      "Least predicted classes:\n",
      "soup bowl : 24\n",
      "English foxhound : 21\n",
      "Windsor tie : 23\n",
      "sunglasses, dark glasses, shades : 25\n",
      "car wheel : 23\n",
      "ram, tup : 21\n",
      "hair spray : 24\n",
      "letter opener, paper knife, paperknife : 22\n",
      "dock, dockage, docking facility : 22\n",
      "projectile, missile : 21\n",
      "typewriter keyboard : 25\n",
      "velvet : 17\n",
      "sunglass : 20\n",
      "tiger cat : 16\n"
     ]
    }
   ],
   "source": [
    "predicted_filtered_max = {key:value for (key,value) in predicted_dict.items() if value >=85  }\n",
    "predicted_filtered_min = {key:value for (key,value) in predicted_dict.items() if value <=25  }\n",
    "\n",
    "print('Most predicted classes:')\n",
    "for key,value in predicted_filtered_max.items():\n",
    " print('{label} : {nb}'.format(label=labels_map[key], nb=value))\n",
    "print('------------------')\n",
    "print('Least predicted classes:')\n",
    "for key,value in predicted_filtered_min.items():\n",
    " print('{label} : {nb}'.format(label=labels_map[key], nb=value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grayscale\n",
    "We compute the metrics on the grayscale images to see if the color have an effect on the inference. Even on small part of the dataset we can see that the accuracy is quite smaller on grayscale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62\n"
     ]
    }
   ],
   "source": [
    "grayscale_labels = [labels[filename] for filename in grayscale  ]\n",
    "results_gray = {key:value for (key,value) in results_dict.items() if key in grayscale_labels }\n",
    "gFP,gFN,gTP,gTN = confusion_values(list(results_gray.keys()),list(results_gray.values()))\n",
    "gmetrics = get_metrics(gFP,gFN,gTP,gTN,len(grayscale_labels))\n",
    "print(gmetrics['ACC'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea40ca8dbc11a9410171efd567f9969a243e602de40adcaaf631b75071b2ebce"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('ml_assign': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
